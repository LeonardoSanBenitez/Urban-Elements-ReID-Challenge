{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d5b47f7e-e48e-435a-a5a6-590cce68a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import zipfile\n",
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import glob\n",
    "import hashlib\n",
    "import shutil\n",
    "\n",
    "config_train = \"config/UrbanElementsReID_train.yml\"  # \"config/UAM_containers.yml\"\n",
    "config_test = \"config/UrbanElementsReID_test.yml\"\n",
    "competition_name = \"urban-reid-challenge\"\n",
    "submission_message = f\"test trained submission\"\n",
    "\n",
    "################ Probably nothing has to be modified from now on ################\n",
    "dataset_path = os.path.join('assets', 'datasets', competition_name)\n",
    "with open(config_train, 'r') as f:\n",
    "    hyperparams = yaml.load(f, Loader=yaml.BaseLoader)\n",
    "model_path = os.path.join(hyperparams['LOG_ROOT'], hyperparams['LOG_NAME'])\n",
    "experiment_id: int = int(time.time())\n",
    "\n",
    "load_dotenv()\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9aab73f9-7452-41a8-91f7-4a41bfb65c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_params_hash(params: Dict[str, Any]) -> str:\n",
    "    stringified = json.dumps({k: str(params[k]) for k in params}, sort_keys=True)\n",
    "    return hashlib.md5(stringified.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b08beda4-3b09-408a-bec7-65e94d333d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /home/benle1/.local/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
      "Requirement already satisfied: timm in /home/benle1/.local/lib/python3.10/site-packages (1.0.15)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
      "Requirement already satisfied: yacs in /home/benle1/.local/lib/python3.10/site-packages (0.1.8)\n",
      "Requirement already satisfied: kaggle in /home/benle1/.local/lib/python3.10/site-packages (1.7.4.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.29.3)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.15.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2025.3.13)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.2.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (78.1.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /home/benle1/.local/lib/python3.10/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: text-unidecode in /home/benle1/.local/lib/python3.10/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.20)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Dataset already existed\n"
     ]
    }
   ],
   "source": [
    "# Depednencies\n",
    "# TODO: move to .def\n",
    "!pip install torch torchvision torchaudio einops timm scikit-image opencv-python tensorboard yacs kaggle pyyaml\n",
    "\n",
    "# Download the dataset\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "    api.competition_download_files(competition_name, path=\"./assets\")\n",
    "    with zipfile.ZipFile(f'./assets/{competition_name}.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(dataset_path)\n",
    "    os.remove(f'./assets/{competition_name}.zip')\n",
    "    print(f\"Downloaded dataset for {competition_name}\")\n",
    "    \n",
    "    %cd assets/datasets/urban-reid-challenge\n",
    "    !mv ./image_query/image_query/* ./image_query/\n",
    "    !rm -r ./image_query/image_query\n",
    "    \n",
    "    !mv ./image_test/image_test/* ./image_test/\n",
    "    !rm -r ./image_test/image_test\n",
    "    \n",
    "    !mv ./image_train/image_train/* ./image_train/\n",
    "    !rm -r ./image_train/image_train\n",
    "    %cd ../../..\n",
    "else:\n",
    "    print(f\"Dataset already existed\")\n",
    "\n",
    "# Download the model\n",
    "os.makedirs('assets/models', exist_ok=True)\n",
    "if not os.path.exists('assets/models/resnet50-19c8e357.pth'):\n",
    "    !curl -o 'assets/models/resnet50-19c8e357.pth' https://download.pytorch.org/models/resnet50-19c8e357.pth\n",
    "if not os.path.exists('assets/models/jx_vit_base_p16_224-80ecf9dd.pth'):\n",
    "    !curl -L -o 'assets/models/jx_vit_base_p16_224-80ecf9dd.pth'  'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039dfdd-40d4-4c81-a1f5-e44e123c1e20",
   "metadata": {},
   "source": [
    "# Train embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0513fd7c-1636-4bb5-8167-951880abf61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  4 02:20:49 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-16GB           On  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              25W / 250W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b3a8cda-2764-4871-b155-f00a6260666f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-04 02:00:49,419 PAT INFO: Saving model in the path :assets/models/PAT\n",
      "2025-04-04 02:00:49,419 PAT INFO: Namespace(config_file='config/UrbanElementsReID_train.yml', opts=[], local_rank=0)\n",
      "2025-04-04 02:00:49,419 PAT INFO: Loaded configuration file config/UrbanElementsReID_train.yml\n",
      "2025-04-04 02:00:49,419 PAT INFO: \n",
      "MODEL:\n",
      "  PRETRAIN_CHOICE: 'imagenet'\n",
      "  #PRETRAIN_PATH: \"../../.cache/torch/hub/checkpoints\" # root of pretrain path\n",
      "  PRETRAIN_PATH: \"assets/models\" \n",
      "  IF_LABELSMOOTH: 'on'\n",
      "  IF_WITH_CENTER: 'no'\n",
      "  NAME: 'part_attention_vit'\n",
      "  NO_MARGIN: True\n",
      "  DEVICE_ID: ('0')\n",
      "  TRANSFORMER_TYPE: 'vit_base_patch16_224_TransReID'\n",
      "  STRIDE_SIZE: [16, 16]\n",
      "\n",
      "INPUT:\n",
      "  SIZE_TRAIN: [256,128]\n",
      "  SIZE_TEST: [256,128]\n",
      "  REA:\n",
      "    ENABLED: False\n",
      "  PIXEL_MEAN: [0.5, 0.5, 0.5]\n",
      "  PIXEL_STD: [0.5, 0.5, 0.5]\n",
      "  LGT: # Local Grayscale Transfomation\n",
      "    DO_LGT: True\n",
      "    PROB: 0.5\n",
      "\n",
      "DATASETS:\n",
      "  TRAIN: ('UrbanElementsReID',)\n",
      "  TEST: ('UrbanElementsReID',)\n",
      "  #ROOT_DIR: ('../../data') # root of datasets\n",
      "  #ROOT_DIR: '/home/jgf/Desktop/rhome/jgf/baselineChallenge/UrbanElementsReID/'\n",
      "  ROOT_DIR: 'assets/datasets/urban-reid-challenge'\n",
      "\n",
      "DATALOADER:\n",
      "  SAMPLER: 'softmax_triplet'\n",
      "  NUM_INSTANCE: 4\n",
      "  NUM_WORKERS: 8\n",
      "\n",
      "SOLVER:\n",
      "  OPTIMIZER_NAME: 'SGD'\n",
      "  MAX_EPOCHS: 1\n",
      "  BASE_LR: 0.001 # 0.0004 for msmt\n",
      "  IMS_PER_BATCH: 64\n",
      "  WARMUP_METHOD: 'linear'\n",
      "  LARGE_FC_LR: False\n",
      "  CHECKPOINT_PERIOD: 1\n",
      "  LOG_PERIOD: 1\n",
      "  EVAL_PERIOD: 1\n",
      "  WEIGHT_DECAY:  1e-4\n",
      "  WEIGHT_DECAY_BIAS: 1e-4\n",
      "  BIAS_LR_FACTOR: 2\n",
      "  SEED: 1234\n",
      "\n",
      "TEST:\n",
      "  EVAL: True\n",
      "  IMS_PER_BATCH: 128\n",
      "  RE_RANKING: False\n",
      "  WEIGHT: ''\n",
      "  NECK_FEAT: 'before'\n",
      "  FEAT_NORM: True\n",
      "\n",
      "LOG_ROOT: 'assets/models/' # root of log file\n",
      "TB_LOG_ROOT: './assets/tb_log/'\n",
      "LOG_NAME: 'PAT'\n",
      "\n",
      "2025-04-04 02:00:49,420 PAT INFO: Running with config:\n",
      "DATALOADER:\n",
      "  CAMERA_TO_DOMAIN: False\n",
      "  DELETE_REM: False\n",
      "  DROP_LAST: False\n",
      "  INDIVIDUAL: False\n",
      "  NAIVE_WAY: True\n",
      "  NUM_INSTANCE: 4\n",
      "  NUM_WORKERS: 8\n",
      "  SAMPLER: softmax_triplet\n",
      "DATASETS:\n",
      "  COMBINEALL: False\n",
      "  ROOT_DIR: assets/datasets/urban-reid-challenge\n",
      "  TEST: ('UrbanElementsReID',)\n",
      "  TRAIN: ('UrbanElementsReID',)\n",
      "INPUT:\n",
      "  CJ:\n",
      "    BRIGHTNESS: 0.15\n",
      "    CONTRAST: 0.15\n",
      "    ENABLED: False\n",
      "    HUE: 0.1\n",
      "    PROB: 1.0\n",
      "    SATURATION: 0.1\n",
      "  DO_AUGMIX: False\n",
      "  DO_AUTOAUG: False\n",
      "  DO_FLIP: True\n",
      "  DO_PAD: True\n",
      "  FLIP_PROB: 0.5\n",
      "  LGT:\n",
      "    DO_LGT: True\n",
      "    PROB: 0.5\n",
      "  PADDING: 10\n",
      "  PADDING_MODE: constant\n",
      "  PIXEL_MEAN: [0.5, 0.5, 0.5]\n",
      "  PIXEL_STD: [0.5, 0.5, 0.5]\n",
      "  REA:\n",
      "    ENABLED: False\n",
      "    MEAN: [123.675, 116.28, 103.53]\n",
      "    PROB: 0.5\n",
      "  RPT:\n",
      "    ENABLED: False\n",
      "    PROB: 0.5\n",
      "  SIZE_TEST: [256, 128]\n",
      "  SIZE_TRAIN: [256, 128]\n",
      "LOG_NAME: PAT\n",
      "LOG_ROOT: assets/models/\n",
      "MODEL:\n",
      "  ATT_DROP_RATE: 0.0\n",
      "  CLUSTER_K: 10\n",
      "  COS_LAYER: False\n",
      "  DEVICE: cuda\n",
      "  DEVICE_ID: 0\n",
      "  DIST_TRAIN: False\n",
      "  DROP_OUT: 0.0\n",
      "  DROP_PATH: 0.1\n",
      "  FREEZE_PATCH_EMBED: True\n",
      "  ID_LOSS_TYPE: softmax\n",
      "  ID_LOSS_WEIGHT: 1.0\n",
      "  IF_LABELSMOOTH: on\n",
      "  IF_WITH_CENTER: no\n",
      "  LAST_STRIDE: 1\n",
      "  METRIC_LOSS_TYPE: triplet\n",
      "  NAME: part_attention_vit\n",
      "  NECK: bnneck\n",
      "  NO_MARGIN: True\n",
      "  PATCH_EMBED_TYPE: \n",
      "  PC_LOSS: True\n",
      "  PC_LR: 1.0\n",
      "  PC_SCALE: 0.02\n",
      "  PRETRAIN_CHOICE: imagenet\n",
      "  PRETRAIN_PATH: assets/models\n",
      "  SOFT_LABEL: True\n",
      "  SOFT_LAMBDA: 0.5\n",
      "  SOFT_WEIGHT: 0.5\n",
      "  STRIDE_SIZE: [16, 16]\n",
      "  TRANSFORMER_TYPE: vit_base_patch16_224_TransReID\n",
      "  TRIPLET_LOSS_WEIGHT: 1.0\n",
      "SOLVER:\n",
      "  BASE_LR: 0.001\n",
      "  BIAS_LR_FACTOR: 2\n",
      "  CENTER_LOSS_WEIGHT: 0.0005\n",
      "  CENTER_LR: 0.5\n",
      "  CHECKPOINT_PERIOD: 1\n",
      "  COSINE_MARGIN: 0.5\n",
      "  COSINE_SCALE: 30\n",
      "  EVAL_PERIOD: 1\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 64\n",
      "  LARGE_FC_LR: False\n",
      "  LOG_PERIOD: 1\n",
      "  MARGIN: 0.3\n",
      "  MAX_EPOCHS: 1\n",
      "  MOMENTUM: 0.9\n",
      "  OPTIMIZER_NAME: SGD\n",
      "  SEED: 1234\n",
      "  STEPS: (40, 70)\n",
      "  WARMUP_EPOCHS: 5\n",
      "  WARMUP_FACTOR: 0.01\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "TB_LOG_ROOT: ./assets/tb_log/\n",
      "TEST:\n",
      "  DIST_MAT: dist_mat.npy\n",
      "  EVAL: True\n",
      "  FEAT_NORM: True\n",
      "  IMS_PER_BATCH: 128\n",
      "  NECK_FEAT: before\n",
      "  RE_RANKING: False\n",
      "  WEIGHT: \n",
      "2025-04-04 02:00:49,449 PAT INFO: => Loaded UrbanElementsReID\n",
      "2025-04-04 02:00:49,449 PAT INFO:   ----------------------------------------\n",
      "2025-04-04 02:00:49,450 PAT INFO:   subset   | # ids | # images | # cameras\n",
      "2025-04-04 02:00:49,450 PAT INFO:   ----------------------------------------\n",
      "2025-04-04 02:00:49,450 PAT INFO:   train    |   288 |     3607 |         3\n",
      "2025-04-04 02:00:49,450 PAT INFO:   ----------------------------------------\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "????????????????? UrbanElementsReID assets/datasets/urban-reid-challenge\n",
      "2025-04-04 02:00:49,489 PAT INFO: => Loaded UrbanElementsReID\n",
      "2025-04-04 02:00:49,489 PAT INFO:   ----------------------------------------\n",
      "2025-04-04 02:00:49,489 PAT INFO:   subset   | # ids | # images | # cameras\n",
      "2025-04-04 02:00:49,489 PAT INFO:   ----------------------------------------\n",
      "2025-04-04 02:00:49,489 PAT INFO:   query    |   288 |     3607 |         3\n",
      "2025-04-04 02:00:49,490 PAT INFO:   gallery  |   288 |     3607 |         3\n",
      "2025-04-04 02:00:49,490 PAT INFO:   ----------------------------------------\n",
      "using Transformer_type: part token vit as a backbone\n",
      "using stride: [16, 16], and patch number is num_y16 * num_x8\n",
      "using drop_out rate is : 0.0\n",
      "using attn_drop_out rate is : 0.0\n",
      "using drop_path rate is : 0.1\n",
      "Resized position embedding from size:torch.Size([1, 197, 768]) to size: torch.Size([1, 132, 768]) with height:16 width: 8\n",
      "Load 153 / 155 layers.\n",
      "Loading pretrained ImageNet model......from assets/models/jx_vit_base_p16_224-80ecf9dd.pth\n",
      "===========building our part attention vit===========\n",
      "2025-04-04 02:00:51,360 PAT.train INFO: Number of parameter: 86.74M\n",
      "====== freeze patch_embed for stability ======\n",
      "using soft triplet loss for training\n",
      "label smooth on, numclasses: 288\n",
      "========using soft label========\n",
      "2025-04-04 02:00:51,562 PAT.train INFO: start training\n",
      "saving tblog to ./assets/tb_log/PAT\n",
      "/home/benle1/Urban-Elements-ReID-Challenge/Code/Files for PAT/processor/part_attention_vit_processor.py:52: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(init_scale=512)\n",
      "initialize the centers\n",
      "initialization done\n",
      "/home/benle1/Urban-Elements-ReID-Challenge/Code/Files for PAT/processor/part_attention_vit_processor.py:99: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(enabled=True):\n",
      "/home/benle1/Urban-Elements-ReID-Challenge/Code/Files for PAT/loss/myloss.py:29: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta = 1, Number alpha = 1) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:1661.)\n",
      "  dist_map.addmm_(1, -2, part_feat, part_centers.t())\n",
      "2025-04-04 02:01:10,314 PAT.train INFO: Epoch[1] Iteration[1/51] total_loss: 12.333, reid_loss: 11.412, pc_loss: 0.920, Acc: 0.000, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:10,575 PAT.train INFO: Epoch[1] Iteration[2/51] total_loss: 11.815, reid_loss: 10.876, pc_loss: 0.938, Acc: 0.008, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:10,812 PAT.train INFO: Epoch[1] Iteration[3/51] total_loss: 11.679, reid_loss: 10.707, pc_loss: 0.972, Acc: 0.005, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:11,058 PAT.train INFO: Epoch[1] Iteration[4/51] total_loss: 11.475, reid_loss: 10.512, pc_loss: 0.963, Acc: 0.016, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:11,332 PAT.train INFO: Epoch[1] Iteration[5/51] total_loss: 11.441, reid_loss: 10.466, pc_loss: 0.975, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:11,623 PAT.train INFO: Epoch[1] Iteration[6/51] total_loss: 11.428, reid_loss: 10.437, pc_loss: 0.991, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:11,917 PAT.train INFO: Epoch[1] Iteration[7/51] total_loss: 11.323, reid_loss: 10.331, pc_loss: 0.993, Acc: 0.011, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:12,180 PAT.train INFO: Epoch[1] Iteration[8/51] total_loss: 11.417, reid_loss: 10.418, pc_loss: 0.999, Acc: 0.012, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:12,464 PAT.train INFO: Epoch[1] Iteration[9/51] total_loss: 11.370, reid_loss: 10.369, pc_loss: 1.001, Acc: 0.010, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:12,732 PAT.train INFO: Epoch[1] Iteration[10/51] total_loss: 11.277, reid_loss: 10.269, pc_loss: 1.008, Acc: 0.011, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:13,029 PAT.train INFO: Epoch[1] Iteration[11/51] total_loss: 11.215, reid_loss: 10.201, pc_loss: 1.014, Acc: 0.010, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:13,328 PAT.train INFO: Epoch[1] Iteration[12/51] total_loss: 11.139, reid_loss: 10.117, pc_loss: 1.021, Acc: 0.010, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:13,584 PAT.train INFO: Epoch[1] Iteration[13/51] total_loss: 11.093, reid_loss: 10.058, pc_loss: 1.035, Acc: 0.010, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:13,864 PAT.train INFO: Epoch[1] Iteration[14/51] total_loss: 11.128, reid_loss: 10.091, pc_loss: 1.037, Acc: 0.009, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:14,114 PAT.train INFO: Epoch[1] Iteration[15/51] total_loss: 11.074, reid_loss: 10.034, pc_loss: 1.039, Acc: 0.009, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:14,435 PAT.train INFO: Epoch[1] Iteration[16/51] total_loss: 11.031, reid_loss: 9.989, pc_loss: 1.042, Acc: 0.009, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:14,729 PAT.train INFO: Epoch[1] Iteration[17/51] total_loss: 11.047, reid_loss: 10.004, pc_loss: 1.043, Acc: 0.011, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:15,016 PAT.train INFO: Epoch[1] Iteration[18/51] total_loss: 11.052, reid_loss: 10.002, pc_loss: 1.051, Acc: 0.010, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:15,263 PAT.train INFO: Epoch[1] Iteration[19/51] total_loss: 11.029, reid_loss: 9.978, pc_loss: 1.052, Acc: 0.012, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:15,566 PAT.train INFO: Epoch[1] Iteration[20/51] total_loss: 11.029, reid_loss: 9.977, pc_loss: 1.052, Acc: 0.011, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:15,832 PAT.train INFO: Epoch[1] Iteration[21/51] total_loss: 11.028, reid_loss: 9.978, pc_loss: 1.050, Acc: 0.011, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:16,091 PAT.train INFO: Epoch[1] Iteration[22/51] total_loss: 11.019, reid_loss: 9.964, pc_loss: 1.055, Acc: 0.011, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:16,425 PAT.train INFO: Epoch[1] Iteration[23/51] total_loss: 11.093, reid_loss: 10.035, pc_loss: 1.058, Acc: 0.011, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:16,704 PAT.train INFO: Epoch[1] Iteration[24/51] total_loss: 11.093, reid_loss: 10.029, pc_loss: 1.064, Acc: 0.011, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:16,992 PAT.train INFO: Epoch[1] Iteration[25/51] total_loss: 11.103, reid_loss: 10.039, pc_loss: 1.064, Acc: 0.012, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:17,270 PAT.train INFO: Epoch[1] Iteration[26/51] total_loss: 11.067, reid_loss: 10.002, pc_loss: 1.064, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:17,566 PAT.train INFO: Epoch[1] Iteration[27/51] total_loss: 11.058, reid_loss: 9.988, pc_loss: 1.069, Acc: 0.012, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:17,820 PAT.train INFO: Epoch[1] Iteration[28/51] total_loss: 11.047, reid_loss: 9.975, pc_loss: 1.073, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:18,095 PAT.train INFO: Epoch[1] Iteration[29/51] total_loss: 11.045, reid_loss: 9.966, pc_loss: 1.078, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:18,397 PAT.train INFO: Epoch[1] Iteration[30/51] total_loss: 11.023, reid_loss: 9.940, pc_loss: 1.082, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:18,663 PAT.train INFO: Epoch[1] Iteration[31/51] total_loss: 11.008, reid_loss: 9.922, pc_loss: 1.086, Acc: 0.014, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:18,917 PAT.train INFO: Epoch[1] Iteration[32/51] total_loss: 11.004, reid_loss: 9.919, pc_loss: 1.085, Acc: 0.014, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:19,173 PAT.train INFO: Epoch[1] Iteration[33/51] total_loss: 11.017, reid_loss: 9.930, pc_loss: 1.088, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:19,445 PAT.train INFO: Epoch[1] Iteration[34/51] total_loss: 11.014, reid_loss: 9.925, pc_loss: 1.089, Acc: 0.014, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:19,657 PAT.train INFO: Epoch[1] Iteration[35/51] total_loss: 10.991, reid_loss: 9.897, pc_loss: 1.094, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:19,865 PAT.train INFO: Epoch[1] Iteration[36/51] total_loss: 10.999, reid_loss: 9.904, pc_loss: 1.095, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:20,071 PAT.train INFO: Epoch[1] Iteration[37/51] total_loss: 10.974, reid_loss: 9.880, pc_loss: 1.094, Acc: 0.014, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:20,279 PAT.train INFO: Epoch[1] Iteration[38/51] total_loss: 10.976, reid_loss: 9.882, pc_loss: 1.094, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:20,485 PAT.train INFO: Epoch[1] Iteration[39/51] total_loss: 10.962, reid_loss: 9.865, pc_loss: 1.097, Acc: 0.014, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:20,694 PAT.train INFO: Epoch[1] Iteration[40/51] total_loss: 10.969, reid_loss: 9.868, pc_loss: 1.101, Acc: 0.013, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:20,900 PAT.train INFO: Epoch[1] Iteration[41/51] total_loss: 10.948, reid_loss: 9.845, pc_loss: 1.103, Acc: 0.015, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:21,108 PAT.train INFO: Epoch[1] Iteration[42/51] total_loss: 10.943, reid_loss: 9.839, pc_loss: 1.103, Acc: 0.016, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:21,321 PAT.train INFO: Epoch[1] Iteration[43/51] total_loss: 10.917, reid_loss: 9.812, pc_loss: 1.105, Acc: 0.016, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:21,528 PAT.train INFO: Epoch[1] Iteration[44/51] total_loss: 10.909, reid_loss: 9.801, pc_loss: 1.108, Acc: 0.017, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:21,738 PAT.train INFO: Epoch[1] Iteration[45/51] total_loss: 10.934, reid_loss: 9.824, pc_loss: 1.111, Acc: 0.021, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:21,944 PAT.train INFO: Epoch[1] Iteration[46/51] total_loss: 10.924, reid_loss: 9.808, pc_loss: 1.115, Acc: 0.021, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:22,152 PAT.train INFO: Epoch[1] Iteration[47/51] total_loss: 10.914, reid_loss: 9.796, pc_loss: 1.118, Acc: 0.021, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:22,360 PAT.train INFO: Epoch[1] Iteration[48/51] total_loss: 10.907, reid_loss: 9.784, pc_loss: 1.122, Acc: 0.021, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:22,566 PAT.train INFO: Epoch[1] Iteration[49/51] total_loss: 10.928, reid_loss: 9.804, pc_loss: 1.124, Acc: 0.023, Base Lr: 2.08e-04\n",
      "2025-04-04 02:01:22,675 PAT.train INFO: Epoch 1 done. Time per batch: 0.337[s] Speed: 190.1[samples/s]\n",
      "2025-04-04 02:01:22,675 PAT.test INFO: Enter inferencing\n",
      "2025-04-04 02:01:48,677 PAT.test INFO: Validation Results \n",
      "2025-04-04 02:01:48,678 PAT.test INFO: mAP: 15.4%\n",
      "2025-04-04 02:01:48,678 PAT.test INFO: CMC curve, Rank-1  :28.9%\n",
      "2025-04-04 02:01:48,678 PAT.test INFO: CMC curve, Rank-5  :52.3%\n",
      "2025-04-04 02:01:48,678 PAT.test INFO: CMC curve, Rank-10 :63.8%\n",
      "2025-04-04 02:01:48,678 PAT.test INFO: total inference time: 26.00\n",
      "2025-04-04 02:01:48,682 PAT.train INFO: =====best epoch: 1=====\n",
      "using Transformer_type: part token vit as a backbone\n",
      "using stride: [16, 16], and patch number is num_y16 * num_x8\n",
      "using drop_out rate is : 0.0\n",
      "using attn_drop_out rate is : 0.0\n",
      "using drop_path rate is : 0.1\n",
      "Resized position embedding from size:torch.Size([1, 197, 768]) to size: torch.Size([1, 132, 768]) with height:16 width: 8\n",
      "Load 153 / 155 layers.\n",
      "Loading pretrained ImageNet model......from assets/models/jx_vit_base_p16_224-80ecf9dd.pth\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "===========building our part attention vit===========\n",
      "2025-04-04 02:01:51,194 PAT.train INFO: Number of parameter: 86.52M\n",
      "Loading trained model from assets/models/PAT/part_attention_vit_1.pth\n",
      "load weights from part_attention_vit_1.pth\n",
      "????????????????? UrbanElementsReID assets/datasets/urban-reid-challenge\n",
      "2025-04-04 02:01:51,640 PAT INFO: => Loaded UrbanElementsReID\n",
      "2025-04-04 02:01:51,640 PAT INFO:   ----------------------------------------\n",
      "2025-04-04 02:01:51,640 PAT INFO:   subset   | # ids | # images | # cameras\n",
      "2025-04-04 02:01:51,640 PAT INFO:   ----------------------------------------\n",
      "2025-04-04 02:01:51,640 PAT INFO:   query    |   288 |     3607 |         3\n",
      "2025-04-04 02:01:51,640 PAT INFO:   gallery  |   288 |     3607 |         3\n",
      "2025-04-04 02:01:51,640 PAT INFO:   ----------------------------------------\n",
      "2025-04-04 02:01:51,640 PAT.test INFO: Enter inferencing\n",
      "2025-04-04 02:02:19,116 PAT.test INFO: Validation Results \n",
      "2025-04-04 02:02:19,117 PAT.test INFO: mAP: 15.3%\n",
      "2025-04-04 02:02:19,117 PAT.test INFO: CMC curve, Rank-1  :28.8%\n",
      "2025-04-04 02:02:19,117 PAT.test INFO: CMC curve, Rank-5  :52.9%\n",
      "2025-04-04 02:02:19,117 PAT.test INFO: CMC curve, Rank-10 :64.0%\n",
      "2025-04-04 02:02:19,117 PAT.test INFO: total inference time: 27.39\n",
      "removing assets/models/PAT/part_attention_vit_1.pth. \n",
      "saving final checkpoint.\n",
      "Do not interrupt the program!!!\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "assert os.path.exists('assets'), 'are you are in the right folder?'\n",
    "assert os.getcwd().endswith('PAT'), 'are you are in the right folder?'\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "!python train.py --config_file {config_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "754e830d-d112-464d-b692-941ff917a047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(os.path.join(model_path, \"part_attention_vit_*.pth\"))\n",
    "max_epoch = max([int(f.split('_')[-1].split('.')[0]) for f in files])\n",
    "assert max_epoch > 0\n",
    "assert os.path.exists(os.path.join(model_path, f'part_attention_vit_{max_epoch}.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5cf707-31e1-43c4-8131-a90d06c6360d",
   "metadata": {},
   "source": [
    "# Generate ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "90e4b060-5b5a-4705-a8d2-bfcc366ef67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assets/models/PAT'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(config_test, 'r') as f:\n",
    "    hyperparams_test = yaml.load(f, Loader=yaml.BaseLoader)\n",
    "assert hyperparams_test['TEST']['WEIGHT'] == os.path.join(model_path, f'part_attention_vit_{max_epoch}.pth'), 'not testing with the trained model...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "022e41fb-d39d-49ee-b3d4-1b3494c2d04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-04 02:10:54,397 PAT INFO: Namespace(config_file='config/UrbanElementsReID_test.yml', opts=[], track='assets/models/PAT/track.txt')\n",
      "2025-04-04 02:10:54,397 PAT INFO: Loaded configuration file config/UrbanElementsReID_test.yml\n",
      "2025-04-04 02:10:54,398 PAT INFO: \n",
      "MODEL:\n",
      "  PRETRAIN_CHOICE: 'imagenet'\n",
      "  #PRETRAIN_PATH: \"../../.cache/torch/hub/checkpoints\" # root of pretrain path\n",
      "  PRETRAIN_PATH: \"assets/models\" \n",
      "  METRIC_LOSS_TYPE: 'triplet'\n",
      "  IF_LABELSMOOTH: 'on'\n",
      "  IF_WITH_CENTER: 'no'\n",
      "  NAME: 'part_attention_vit'\n",
      "  NO_MARGIN: True\n",
      "  DEVICE_ID: ('0')\n",
      "  TRANSFORMER_TYPE: 'vit_base_patch16_224_TransReID'\n",
      "  STRIDE_SIZE: [16, 16]\n",
      "\n",
      "INPUT:\n",
      "  SIZE_TRAIN: [256,128]\n",
      "  SIZE_TEST: [256,128]\n",
      "  REA:\n",
      "    ENABLED: False\n",
      "  PIXEL_MEAN: [0.5, 0.5, 0.5]\n",
      "  PIXEL_STD: [0.5, 0.5, 0.5]\n",
      "  LGT: # Local Grayscale Transfomation\n",
      "    DO_LGT: True\n",
      "    PROB: 0.5\n",
      "\n",
      "DATASETS:\n",
      "  TRAIN: ('UrbanElementsReID',)\n",
      "  TEST: ('UrbanElementsReID_test',)\n",
      "  #ROOT_DIR: ('../../data') # root of datasets\n",
      "  #ROOT_DIR: '/home/jgf/Desktop/rhome/jgf/baselineChallenge/UrbanElementsReID/'\n",
      "  ROOT_DIR: 'assets/datasets/urban-reid-challenge'\n",
      "\n",
      "\n",
      "DATALOADER:\n",
      "  SAMPLER: 'softmax_triplet'\n",
      "  NUM_INSTANCE: 4\n",
      "  NUM_WORKERS: 8\n",
      "\n",
      "SOLVER:\n",
      "  OPTIMIZER_NAME: 'SGD'\n",
      "  MAX_EPOCHS: 60\n",
      "  BASE_LR: 0.001 # 0.0004 for msmt\n",
      "  IMS_PER_BATCH: 64\n",
      "  WARMUP_METHOD: 'linear'\n",
      "  LARGE_FC_LR: False\n",
      "  CHECKPOINT_PERIOD: 5\n",
      "  LOG_PERIOD: 60\n",
      "  EVAL_PERIOD: 1\n",
      "  WEIGHT_DECAY:  1e-4\n",
      "  WEIGHT_DECAY_BIAS: 1e-4\n",
      "  BIAS_LR_FACTOR: 2\n",
      "  SEED: 1234\n",
      "\n",
      "TEST:\n",
      "  EVAL: True\n",
      "  IMS_PER_BATCH: 128\n",
      "  RE_RANKING: False\n",
      "  WEIGHT: \"assets/models/PAT/part_attention_vit_1.pth\" #test \n",
      "  NECK_FEAT: 'before'\n",
      "  FEAT_NORM: True\n",
      "\n",
      "LOG_ROOT: 'assets/models/' # root of log file\n",
      "TB_LOG_ROOT: './assets/tb_log/'\n",
      "LOG_NAME: 'PAT'\n",
      "2025-04-04 02:10:54,398 PAT INFO: Running with config:\n",
      "DATALOADER:\n",
      "  CAMERA_TO_DOMAIN: False\n",
      "  DELETE_REM: False\n",
      "  DROP_LAST: False\n",
      "  INDIVIDUAL: False\n",
      "  NAIVE_WAY: True\n",
      "  NUM_INSTANCE: 4\n",
      "  NUM_WORKERS: 8\n",
      "  SAMPLER: softmax_triplet\n",
      "DATASETS:\n",
      "  COMBINEALL: False\n",
      "  ROOT_DIR: assets/datasets/urban-reid-challenge\n",
      "  TEST: ('UrbanElementsReID_test',)\n",
      "  TRAIN: ('UrbanElementsReID',)\n",
      "INPUT:\n",
      "  CJ:\n",
      "    BRIGHTNESS: 0.15\n",
      "    CONTRAST: 0.15\n",
      "    ENABLED: False\n",
      "    HUE: 0.1\n",
      "    PROB: 1.0\n",
      "    SATURATION: 0.1\n",
      "  DO_AUGMIX: False\n",
      "  DO_AUTOAUG: False\n",
      "  DO_FLIP: True\n",
      "  DO_PAD: True\n",
      "  FLIP_PROB: 0.5\n",
      "  LGT:\n",
      "    DO_LGT: True\n",
      "    PROB: 0.5\n",
      "  PADDING: 10\n",
      "  PADDING_MODE: constant\n",
      "  PIXEL_MEAN: [0.5, 0.5, 0.5]\n",
      "  PIXEL_STD: [0.5, 0.5, 0.5]\n",
      "  REA:\n",
      "    ENABLED: False\n",
      "    MEAN: [123.675, 116.28, 103.53]\n",
      "    PROB: 0.5\n",
      "  RPT:\n",
      "    ENABLED: False\n",
      "    PROB: 0.5\n",
      "  SIZE_TEST: [256, 128]\n",
      "  SIZE_TRAIN: [256, 128]\n",
      "LOG_NAME: PAT\n",
      "LOG_ROOT: assets/models/\n",
      "MODEL:\n",
      "  ATT_DROP_RATE: 0.0\n",
      "  CLUSTER_K: 10\n",
      "  COS_LAYER: False\n",
      "  DEVICE: cuda\n",
      "  DEVICE_ID: 0\n",
      "  DIST_TRAIN: False\n",
      "  DROP_OUT: 0.0\n",
      "  DROP_PATH: 0.1\n",
      "  FREEZE_PATCH_EMBED: True\n",
      "  ID_LOSS_TYPE: softmax\n",
      "  ID_LOSS_WEIGHT: 1.0\n",
      "  IF_LABELSMOOTH: on\n",
      "  IF_WITH_CENTER: no\n",
      "  LAST_STRIDE: 1\n",
      "  METRIC_LOSS_TYPE: triplet\n",
      "  NAME: part_attention_vit\n",
      "  NECK: bnneck\n",
      "  NO_MARGIN: True\n",
      "  PATCH_EMBED_TYPE: \n",
      "  PC_LOSS: True\n",
      "  PC_LR: 1.0\n",
      "  PC_SCALE: 0.02\n",
      "  PRETRAIN_CHOICE: imagenet\n",
      "  PRETRAIN_PATH: assets/models\n",
      "  SOFT_LABEL: True\n",
      "  SOFT_LAMBDA: 0.5\n",
      "  SOFT_WEIGHT: 0.5\n",
      "  STRIDE_SIZE: [16, 16]\n",
      "  TRANSFORMER_TYPE: vit_base_patch16_224_TransReID\n",
      "  TRIPLET_LOSS_WEIGHT: 1.0\n",
      "SOLVER:\n",
      "  BASE_LR: 0.001\n",
      "  BIAS_LR_FACTOR: 2\n",
      "  CENTER_LOSS_WEIGHT: 0.0005\n",
      "  CENTER_LR: 0.5\n",
      "  CHECKPOINT_PERIOD: 5\n",
      "  COSINE_MARGIN: 0.5\n",
      "  COSINE_SCALE: 30\n",
      "  EVAL_PERIOD: 1\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 64\n",
      "  LARGE_FC_LR: False\n",
      "  LOG_PERIOD: 60\n",
      "  MARGIN: 0.3\n",
      "  MAX_EPOCHS: 60\n",
      "  MOMENTUM: 0.9\n",
      "  OPTIMIZER_NAME: SGD\n",
      "  SEED: 1234\n",
      "  STEPS: (40, 70)\n",
      "  WARMUP_EPOCHS: 5\n",
      "  WARMUP_FACTOR: 0.01\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "TB_LOG_ROOT: ./assets/tb_log/\n",
      "TEST:\n",
      "  DIST_MAT: dist_mat.npy\n",
      "  EVAL: True\n",
      "  FEAT_NORM: True\n",
      "  IMS_PER_BATCH: 128\n",
      "  NECK_FEAT: before\n",
      "  RE_RANKING: False\n",
      "  WEIGHT: assets/models/PAT/part_attention_vit_1.pth\n",
      "using Transformer_type: part token vit as a backbone\n",
      "using stride: [16, 16], and patch number is num_y16 * num_x8\n",
      "using drop_out rate is : 0.0\n",
      "using attn_drop_out rate is : 0.0\n",
      "using drop_path rate is : 0.1\n",
      "Resized position embedding from size:torch.Size([1, 197, 768]) to size: torch.Size([1, 132, 768]) with height:16 width: 8\n",
      "Load 153 / 155 layers.\n",
      "Loading pretrained ImageNet model......from assets/models/jx_vit_base_p16_224-80ecf9dd.pth\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "===========building our part attention vit===========\n",
      "2025-04-04 02:10:56,265 PAT.train INFO: Number of parameter: 86.52M\n",
      "Loading trained model from assets/models/PAT/part_attention_vit_1.pth\n",
      ">>>>>>>>>>>>>>>>>>>>>>> UrbanElementsReID_test\n",
      "????????????????? UrbanElementsReID_test assets/datasets/urban-reid-challenge\n",
      "2025-04-04 02:10:56,904 PAT INFO: => Loaded UrbanElementsReID_test\n",
      "2025-04-04 02:10:56,905 PAT INFO:   ----------------------------------------\n",
      "2025-04-04 02:10:56,905 PAT INFO:   subset   | # ids | # images | # cameras\n",
      "2025-04-04 02:10:56,905 PAT INFO:   ----------------------------------------\n",
      "2025-04-04 02:10:56,905 PAT INFO:   query    |     1 |      346 |         1\n",
      "2025-04-04 02:10:56,905 PAT INFO:   gallery  |     1 |     1008 |         3\n",
      "2025-04-04 02:10:56,905 PAT INFO:   ----------------------------------------\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "2025-04-04 02:10:56,906 PAT.test INFO: Enter inferencing\n",
      "2025-04-04 02:11:04,390 PAT.test INFO: Validation Results \n",
      "2025-04-04 02:11:04,390 PAT.test INFO: mAP: 100.0%\n",
      "2025-04-04 02:11:04,390 PAT.test INFO: CMC curve, Rank-1  :100.0%\n",
      "2025-04-04 02:11:04,390 PAT.test INFO: CMC curve, Rank-5  :100.0%\n",
      "2025-04-04 02:11:04,390 PAT.test INFO: CMC curve, Rank-10 :100.0%\n",
      "2025-04-04 02:11:04,390 PAT.test INFO: total inference time: 7.40\n"
     ]
    }
   ],
   "source": [
    "!python update.py --config_file {config_test} --track {os.path.join(model_path, \"track.txt\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3397a82e-b465-42a6-a3d8-deb7bf395fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file_name = os.path.join(model_path, \"track_submission.csv\")\n",
    "assert os.path.exists(submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e343db-277b-448c-b75e-e25a1f6037c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r {model_path} {model_path}_backup_{experiment_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb2dd26-edd5-46b2-a7d7-f9c99c87856c",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "87d10dd9-d401-4ea1-9080-7a4aee95fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(submission_file_name)\n",
    "df = pd.read_csv(submission_file_name)\n",
    "assert df.shape[1] == 2\n",
    "assert df.shape[0] > 100\n",
    "\n",
    "submission_message += f\"; commit_hash: {subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode('ascii').strip()}\"\n",
    "submission_message += f\"; hyperparameters_hash: {calculate_params_hash(hyperparams)}\"\n",
    "submission_message += f\"; experiment_ID: {experiment_id}\"\n",
    "print(f'Submitting with message \"{submission_message}\"')\n",
    "\n",
    "# Submit the file to the competition\n",
    "# Uncomment only for actual submissions!\n",
    "#api.competition_submit(submission_file_name, submission_message, competition_name)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
