{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2fa01f-745b-4cc0-accd-1d9c642b27ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import dotenv\n",
    "import time\n",
    "import glob\n",
    "import hashlib\n",
    "import shutil\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "config_test_patplusplus = \"config/UrbanElementsReID_test_patplusplus.yml\"\n",
    "track = \"assets/models/PAT_plusplus/track.txt\"\n",
    "submission_file_name = \"assets/models/PAT_plusplus/track_submission.csv\"\n",
    "\n",
    "competition_name = \"urban-reid-challenge\"\n",
    "submission_message = f\"PAT++, simple matching\"\n",
    "\n",
    "################ Probably nothing has to be modified from now on ################\n",
    "\n",
    "assert dotenv.load_dotenv('../../.env')\n",
    "assert os.getenv('KAGGLE_USERNAME')\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "logging.root.setLevel(logging.INFO)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    logging.warning(\"Where is your GPU dude?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cc1e795-e267-428b-b415-5d3d2ffbbf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:06:24,414 PAT INFO: Namespace(config_file='config/UrbanElementsReID_test_patplusplus.yml', opts=[], track='assets/models/PAT_plusplus/track.txt')\n",
      "2025-05-12 00:06:24,414 PAT INFO: Loaded configuration file config/UrbanElementsReID_test_patplusplus.yml\n",
      "2025-05-12 00:06:24,415 PAT INFO: \n",
      "MODEL:\n",
      "  PRETRAIN_CHOICE: 'imagenet'\n",
      "  #PRETRAIN_PATH: \"../../.cache/torch/hub/checkpoints\" # root of pretrain path\n",
      "  PRETRAIN_PATH: \"assets/models/PAT_r\" \n",
      "  METRIC_LOSS_TYPE: 'triplet'\n",
      "  IF_LABELSMOOTH: 'on'\n",
      "  IF_WITH_CENTER: 'no'\n",
      "  NAME: 'part_attention_vit'\n",
      "  NO_MARGIN: True\n",
      "  DEVICE_ID: ('0')\n",
      "  TRANSFORMER_TYPE: 'vit_base_patch16_224_TransReID'\n",
      "  STRIDE_SIZE: [16, 16]\n",
      "\n",
      "INPUT:\n",
      "  SIZE_TRAIN: [256,128]\n",
      "  SIZE_TEST: [256,128]\n",
      "  REA:\n",
      "    ENABLED: False\n",
      "  PIXEL_MEAN: [0.5, 0.5, 0.5]\n",
      "  PIXEL_STD: [0.5, 0.5, 0.5]\n",
      "  LGT: # Local Grayscale Transfomation\n",
      "    DO_LGT: True\n",
      "    PROB: 0.5\n",
      "\n",
      "DATASETS:\n",
      "  TRAIN: ('UrbanElementsReID',)\n",
      "  TEST: ('UrbanElementsReID_test',)\n",
      "  #ROOT_DIR: ('../../data') # root of datasets\n",
      "  #ROOT_DIR: '/home/jgf/Desktop/rhome/jgf/baselineChallenge/UrbanElementsReID/'\n",
      "  ROOT_DIR: 'assets/datasets/urban-reid-challenge-original'\n",
      "\n",
      "\n",
      "DATALOADER:\n",
      "  SAMPLER: 'softmax_triplet'\n",
      "  NUM_INSTANCE: 4\n",
      "  NUM_WORKERS: 8\n",
      "\n",
      "SOLVER:\n",
      "  OPTIMIZER_NAME: 'SGD'\n",
      "  MAX_EPOCHS: 60\n",
      "  BASE_LR: 0.001 # 0.0004 for msmt\n",
      "  IMS_PER_BATCH: 64\n",
      "  WARMUP_METHOD: 'linear'\n",
      "  LARGE_FC_LR: False\n",
      "  CHECKPOINT_PERIOD: 5\n",
      "  LOG_PERIOD: 60\n",
      "  EVAL_PERIOD: 1\n",
      "  WEIGHT_DECAY:  1e-4\n",
      "  WEIGHT_DECAY_BIAS: 1e-4\n",
      "  BIAS_LR_FACTOR: 2\n",
      "  SEED: 1234\n",
      "\n",
      "TEST:\n",
      "  EVAL: True\n",
      "  IMS_PER_BATCH: 128\n",
      "  RE_RANKING: False\n",
      "  WEIGHT: \"assets/models/PAT_plusplus/part_attention_vit_60.pth\" #test model (epoch number should coincide with the trained epochs)\n",
      "  NECK_FEAT: 'before'\n",
      "  FEAT_NORM: True\n",
      "\n",
      "LOG_ROOT: 'assets/models/' # root of log file\n",
      "TB_LOG_ROOT: './assets/tb_log/'\n",
      "LOG_NAME: 'PAT_plusplus'\n",
      "2025-05-12 00:06:24,415 PAT INFO: Running with config:\n",
      "DATALOADER:\n",
      "  CAMERA_TO_DOMAIN: False\n",
      "  DELETE_REM: False\n",
      "  DROP_LAST: False\n",
      "  INDIVIDUAL: False\n",
      "  NAIVE_WAY: True\n",
      "  NUM_INSTANCE: 4\n",
      "  NUM_WORKERS: 8\n",
      "  SAMPLER: softmax_triplet\n",
      "DATASETS:\n",
      "  COMBINEALL: False\n",
      "  ROOT_DIR: assets/datasets/urban-reid-challenge-original\n",
      "  TEST: ('UrbanElementsReID_test',)\n",
      "  TRAIN: ('UrbanElementsReID',)\n",
      "INPUT:\n",
      "  CJ:\n",
      "    BRIGHTNESS: 0.15\n",
      "    CONTRAST: 0.15\n",
      "    ENABLED: False\n",
      "    HUE: 0.1\n",
      "    PROB: 1.0\n",
      "    SATURATION: 0.1\n",
      "  DO_AUGMIX: False\n",
      "  DO_AUTOAUG: False\n",
      "  DO_FLIP: True\n",
      "  DO_PAD: True\n",
      "  FLIP_PROB: 0.5\n",
      "  LGT:\n",
      "    DO_LGT: True\n",
      "    PROB: 0.5\n",
      "  PADDING: 10\n",
      "  PADDING_MODE: constant\n",
      "  PIXEL_MEAN: [0.5, 0.5, 0.5]\n",
      "  PIXEL_STD: [0.5, 0.5, 0.5]\n",
      "  REA:\n",
      "    ENABLED: False\n",
      "    MEAN: [123.675, 116.28, 103.53]\n",
      "    PROB: 0.5\n",
      "  RPT:\n",
      "    ENABLED: False\n",
      "    PROB: 0.5\n",
      "  SIZE_TEST: [256, 128]\n",
      "  SIZE_TRAIN: [256, 128]\n",
      "LOG_NAME: PAT_plusplus\n",
      "LOG_ROOT: assets/models/\n",
      "MODEL:\n",
      "  ATT_DROP_RATE: 0.0\n",
      "  CLUSTER_K: 10\n",
      "  COS_LAYER: False\n",
      "  DEVICE: cuda\n",
      "  DEVICE_ID: 0\n",
      "  DIST_TRAIN: False\n",
      "  DROP_OUT: 0.0\n",
      "  DROP_PATH: 0.1\n",
      "  FREEZE_PATCH_EMBED: True\n",
      "  ID_LOSS_TYPE: softmax\n",
      "  ID_LOSS_WEIGHT: 1.0\n",
      "  IF_LABELSMOOTH: on\n",
      "  IF_WITH_CENTER: no\n",
      "  LAST_STRIDE: 1\n",
      "  METRIC_LOSS_TYPE: triplet\n",
      "  NAME: part_attention_vit\n",
      "  NECK: bnneck\n",
      "  NO_MARGIN: True\n",
      "  PATCH_EMBED_TYPE: \n",
      "  PC_LOSS: True\n",
      "  PC_LR: 1.0\n",
      "  PC_SCALE: 0.02\n",
      "  PRETRAIN_CHOICE: imagenet\n",
      "  PRETRAIN_PATH: assets/models/PAT_r\n",
      "  SOFT_LABEL: True\n",
      "  SOFT_LAMBDA: 0.5\n",
      "  SOFT_WEIGHT: 0.5\n",
      "  STRIDE_SIZE: [16, 16]\n",
      "  TRANSFORMER_TYPE: vit_base_patch16_224_TransReID\n",
      "  TRIPLET_LOSS_WEIGHT: 1.0\n",
      "SOLVER:\n",
      "  BASE_LR: 0.001\n",
      "  BIAS_LR_FACTOR: 2\n",
      "  CENTER_LOSS_WEIGHT: 0.0005\n",
      "  CENTER_LR: 0.5\n",
      "  CHECKPOINT_PERIOD: 5\n",
      "  COSINE_MARGIN: 0.5\n",
      "  COSINE_SCALE: 30\n",
      "  EVAL_PERIOD: 1\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 64\n",
      "  LARGE_FC_LR: False\n",
      "  LOG_PERIOD: 60\n",
      "  MARGIN: 0.3\n",
      "  MAX_EPOCHS: 60\n",
      "  MOMENTUM: 0.9\n",
      "  OPTIMIZER_NAME: SGD\n",
      "  SEED: 1234\n",
      "  STEPS: (40, 70)\n",
      "  WARMUP_EPOCHS: 5\n",
      "  WARMUP_FACTOR: 0.01\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "TB_LOG_ROOT: ./assets/tb_log/\n",
      "TEST:\n",
      "  DIST_MAT: dist_mat.npy\n",
      "  EVAL: True\n",
      "  FEAT_NORM: True\n",
      "  IMS_PER_BATCH: 128\n",
      "  NECK_FEAT: before\n",
      "  RE_RANKING: False\n",
      "  WEIGHT: assets/models/PAT_plusplus/part_attention_vit_60.pth\n",
      "using Transformer_type: part token vit as a backbone\n",
      "using stride: [16, 16], and patch number is num_y16 * num_x8\n",
      "using drop_out rate is : 0.0\n",
      "using attn_drop_out rate is : 0.0\n",
      "using drop_path rate is : 0.1\n",
      "Load 158 / 155 layers.\n",
      "Loading pretrained ImageNet model......from assets/models/PAT_r/jx_vit_base_p16_224-80ecf9dd.pth\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "===========building our part attention vit===========\n",
      "2025-05-12 00:06:26,193 PAT.train INFO: Number of parameter: 86.52M\n",
      "Loading trained model from assets/models/PAT_plusplus/part_attention_vit_60.pth\n",
      "2025-05-12 00:06:26,772 PAT INFO: => Loaded UrbanElementsReID_test\n",
      "INFO:PAT:=> Loaded UrbanElementsReID_test\n",
      "2025-05-12 00:06:26,772 PAT INFO:   ----------------------------------------\n",
      "INFO:PAT:  ----------------------------------------\n",
      "2025-05-12 00:06:26,772 PAT INFO:   subset   | # ids | # images | # cameras\n",
      "INFO:PAT:  subset   | # ids | # images | # cameras\n",
      "2025-05-12 00:06:26,772 PAT INFO:   ----------------------------------------\n",
      "INFO:PAT:  ----------------------------------------\n",
      "2025-05-12 00:06:26,772 PAT INFO:   query    |     1 |      346 |         1\n",
      "INFO:PAT:  query    |     1 |      346 |         1\n",
      "2025-05-12 00:06:26,773 PAT INFO:   gallery  |     1 |     1008 |         3\n",
      "INFO:PAT:  gallery  |     1 |     1008 |         3\n",
      "2025-05-12 00:06:26,773 PAT INFO:   ----------------------------------------\n",
      "INFO:PAT:  ----------------------------------------\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "2025-05-12 00:06:26,774 PAT.test INFO: Enter inferencing\n",
      "INFO:PAT.test:Enter inferencing\n",
      "2025-05-12 00:06:33,583 PAT.test INFO: Validation Results \n",
      "INFO:PAT.test:Validation Results \n",
      "2025-05-12 00:06:33,584 PAT.test INFO: mAP: 100.0%\n",
      "INFO:PAT.test:mAP: 100.0%\n",
      "2025-05-12 00:06:33,584 PAT.test INFO: CMC curve, Rank-1  :100.0%\n",
      "INFO:PAT.test:CMC curve, Rank-1  :100.0%\n",
      "2025-05-12 00:06:33,584 PAT.test INFO: CMC curve, Rank-5  :100.0%\n",
      "INFO:PAT.test:CMC curve, Rank-5  :100.0%\n",
      "2025-05-12 00:06:33,584 PAT.test INFO: CMC curve, Rank-10 :100.0%\n",
      "INFO:PAT.test:CMC curve, Rank-10 :100.0%\n",
      "2025-05-12 00:06:33,584 PAT.test INFO: total inference time: 6.72\n",
      "INFO:PAT.test:total inference time: 6.72\n",
      "???????????????????????????????? (1008, 768)\n",
      "qf (346, 768)\n",
      "qf_A (0, 768)\n",
      "qf_B (0, 768)\n",
      "qf_C (0, 768)\n",
      "Query_Gallery_dist = (346, 1008)\n",
      "Query_Query_dist = (346, 346)\n",
      "Galery_Galery_dist = (1008, 1008)\n"
     ]
    }
   ],
   "source": [
    "!python update.py --config_file {config_test_patplusplus} --track {track}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a65927-56a6-4d89-9b4e-968faac26aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 331M\n",
      "drwxr-xr-x.  2 benle1 benle1 4.0K May 11 23:51 .\n",
      "drwxr-xr-x. 36 benle1 benle1 4.0K May 11 21:01 ..\n",
      "-rw-r--r--.  1 benle1 benle1 331M May 11 23:51 part_attention_vit_60.pth\n",
      "-rw-r--r--.  1 benle1 benle1 5.1K May 12 00:06 test_log.txt\n",
      "-rw-r--r--.  1 benle1 benle1 132K May 12 00:06 track.txt\n",
      "-rw-r--r--.  1 benle1 benle1 136K May 12 00:06 track_submission.csv\n",
      "-rw-r--r--.  1 benle1 benle1  37K May 11 23:51 train_log.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lah assets/models/PAT_plusplus/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f9a90-9aa7-4617-8a9a-2914b56c2cdf",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb6cde00-a380-4511-8500-e74548c374d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Submitting with message \"PAT++, simple matching; commit_hash: 9b3d05be76bd8535482da8c6d8d63b134e3a8468\"\n",
      "100%|██████████| 135k/135k [00:00<00:00, 181kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"message\": \"Successfully submitted to Urban Elements ReID Challenge\", \"ref\": 44686968}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_message += f\"; commit_hash: {subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode('ascii').strip()}\"\n",
    "logging.info(f'Submitting with message \"{submission_message}\"')\n",
    "\n",
    "api.competition_submit(submission_file_name, submission_message, competition_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01a6c6-ffa2-4a90-9b9a-cbe8e364f805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
